\documentclass[a4paper]{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\usepackage{Sweavel}



\usepackage{listings}
\usepackage{inconsolata}


%-----------------
%Define the colors you want to use

\definecolor{keywordcolor}{rgb}{0,0.6,0.6}
\definecolor{delimcolor}{rgb}{0.461,0.039,0.102}
\definecolor{Rcommentcolor}{rgb}{0.101,0.043,0.432}
%-----------------
%Set up your listings. You can type `texdoc listings` in your terminal
% \lstset{breaklines=true,showstringspaces=false} % this is the alternative way to set up style

\lstdefinestyle{Rsettings}{
  language=R,
  basicstyle=\ttfamily,
  breaklines=true,
  showstringspaces=false,
  keywords={if, else, function, theFunction, tmp},
  otherkeywords={},
  commentstyle=\itshape\color{Rcommentcolor},
  keywordstyle=\color{keywordcolor},
  moredelim=[s][\color{delimcolor}]{"}{"},
}


% \documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}


\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
            bookmarks=true,
            bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
            breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]{hyperref}
\hypersetup{pdfstartview={XYZ null null 1}}

\usepackage{breakurl}

\usepackage{amsmath}
\usepackage{eucal}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{hypernat}
\usepackage{times}
\usepackage{epsfig}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{cancel}


%%% self-defined commands 
\newcommand{\bmat}{\begin{pmatrix}}
\newcommand{\emat}{\end{pmatrix}}
\newcommand{\independent}{\perp\!\!\!\perp}
\newcommand{\todo}[1]{{\it\textcolor{blue}{#1}}} % makes content blue
\newcommand{\tbf}[1]{{\textbf{#1}}}
\newcommand{\vb}[1]{{\verb|#1|}}
\newcommand{\vnorm}[1]{{\lVert #1\rVert}}

\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\benum}{\begin{enumerate}} 
\newcommand{\eenum}{\end{enumerate}}
\newcommand{\bv}{\begin{verbatim}}
\newcommand{\ev}{\end{verbatim}}
\newcommand{\pref}[1]{\protect\ref{#1}}
\newcommand{\plab}[1]{\protect\label{#1}}
\newcommand{\be}{\begin{eqnarray}}
\newcommand{\bes}{\begin{eqnarray*}}
\newcommand{\ee}{\end{eqnarray}}
\newcommand{\ees}{\end{eqnarray*}}
\newcommand{\bm}[1]{\mbox{\boldmath $#1$}}
\newcommand{\tm}[1]{\mbox{\tiny{$#1$}}}
\newcommand{\vc}[2]{\mbox{$ \left[ \begin{array}{c} #1\\ \vdots \\ #2 
 \end{array} \right] $}}
\newcommand{\mt}[4]{\mbox{$ \left[ \begin{array}{c,c,c} #1 & \cdots & #2\\ 
 \vdots & \ddots & \vdots\\ #3 & \cdots & #4 \end{array} \right] $}}
\newcommand{\R}{ {\bf \sffamily R } }
\newcommand{\E}{\textbf{E}}
\newcommand{\var}{\mbox{Var}\,}
\newcommand{\yR}{ {\bf R } }

\newcommand{\non}{\nonumber}
\newcommand{\noi}{\noindent}

\graphicspath{{/Users/joyce/Documents/yuan/INLASPDEPDRA/bluewhales/plots//}}

%%% only for this file 
% \newcommand{\bmv1v2v3}{$(\bm{v}_1\bm{v}_2, \bm{v}_3)$}

\begin{document}



% options(replace.assign = TRUE, width=60)
% the above is the alternative way to set up the chunk, more detail can be found 
%http://tex.stackexchange.com/questions/100088/r-code-linebreaks-and-code-highlighting-in-knitr
% render_listings() put code and output in separate boxes 
% @

% <<setup, include=FALSE, cache=FALSE>>=
%   library(knitr)
% # set global chunk options
% opts_chunk$set(fig.path='/Users/joyce/Documents/yuan/INLASPDEPDRA/DolphinRworking/plots/', fig.align='center', fig.show='hold')
% options(replace.assign=TRUE,width=60)
% @



% \title{Modelling Line Transect survey data as a filtered point process in INLA}
% % \author{Y.Yuan, F. Lingren, J.B. Illian, D.L. Borchers, R. Haavard, T, Gerrodette}
% \maketitle
% \newpage
% \pagenumbering{roman}\setcounter{page}{1}
% 
% \tableofcontents
% \newpage
% \pagenumbering{arabic} \setcounter{page}{1}
% \newpage







{\Large{\textbf{Modelling Line Transect survey data as a filtered point process in INLA}}}
\section{Introduction}
In this paper, we would like to show how to use INLA package to analyse line transect survey data, in particular the density surfance depends on at least one environmental covrariate and the detection function is assumed to be half normal and only depends on the distance perpendicular to the transect line. We use a suitbale dataset to illustrate the method and provides details about how the model is implemented in INLA. 

In general, we need three datasets to construct a filtered point process model for the line trasnect survey data: 1) the obervation data which include all the information for each sighting; 2) the effort data which specify the location for each transect line and 3) the covariate data which provides the covariates for the whole survey area. Unlike other methods (add ref here), we need the covraties not just on the sample area, but for the whole survey area. The filtered point process is defined on the whole survey area. 


\textcolor{blue}{Add ref here to introduce the idea of using point process model to analyse line transect data, what has been done here and what is new in this paper. }


\section{blue whales: data exploring and preliminary analysis}



\begin{Schunk}
\begin{Sinput}
sightorig = read.csv(file = paste(datadir, "Bmus86_06.csv", sep = ""), 
    head = TRUE, sep = ",")
head(sightorig)
\end{Sinput}
\begin{Soutput}
  Sp1 Sp2 Sp3 Sp4 Cruz Sght E Obs Year Month Day Time    Lat
1  75  NA  NA  NA 1267    1 1   7 1989    11  11  639 10.619
2  75  NA  NA  NA 1081    1 1  51 1987     8  10  816 26.513
3  75  NA  NA  NA 1268    1 1  55 1989     9  24  826 -1.256
4  75  NA  NA  NA 1267    1 0   4 1989    10  22 1320 10.221
5  75  NA  NA  NA 1614    1 1 198 1999     7  28 1622 31.731
6  75  NA  NA  NA 1370    1 1  55 1990    12   2  658 21.641
     Long   GS TotGS   PD Bf SH  SD RF HS VS WSp WDi Cue Me Ph Bi
1  -98.95 1.16  1.16 1.37  2 -1  -1  1  1  3  -1  -1   6  4 -1  0
2 -116.18 2.32  2.32 0.78  2 -1  -1  1 -1 -1  -1  -1   6  4 -1  0
3  -91.31 2.32  2.32 1.59  4 -1  -1  2 -1 -1  -1  -1   6  5 -1  0
4  -98.36 1.16  1.16 0.56  5 -1  -1  2  7  1  -1  -1   6  6 -1  0
5 -116.94 2.32  2.32 0.93  3  4 302  1  3  2  13 323   6  4  0  0
6 -115.47 2.76  2.76 0.16  5 -1  -1  1  4  3  -1  -1   6  5 -1  0
  Mx Crs  SST  Vis Angl Retcl RadD InitID MSp
1  0  65 27.2 -1.9   21   1.0 3.84     -1  -1
2  0 154 21.7 -1.9   20   2.4 2.27     -1  -1
3  0 120 19.4 -1.9   35  -1.0 2.78     -1  -1
4  0 323 26.1 -1.9  330  -1.0 1.11     -1  -1
5  0 156 -1.0 11.1  346   1.0 3.83     -1  -1
6  0 343 -1.0 -1.9  350  -1.0 0.93     -1  -1
\end{Soutput}
\begin{Sinput}
nrow(sightorig)
\end{Sinput}
\begin{Soutput}
[1] 266
\end{Soutput}
\begin{Sinput}
## get rid of the non-LT-mode sightings
sightdat = sightorig[sightorig$E == 1, ]
nrow(sightdat)  ## no. of sightings at the LT mode 
\end{Sinput}
\begin{Soutput}
[1] 195
\end{Soutput}
\begin{Sinput}
nrow(sightdat.allmode[sightdat.allmode$E == 0, ])
\end{Sinput}
\begin{Soutput}
Error: object 'sightdat.allmode' not found
\end{Soutput}
\begin{Sinput}
## Tim commented that it is not LT mode if Bft>5
sightdat = sightdat[sightdat$Bf <= 5, ]
unique(sightdat$Bf)
\end{Sinput}
\begin{Soutput}
[1] 2 4 3 5 1 0
\end{Soutput}
\begin{Sinput}
## after excluding all sightings that are not LT mode
nrow(sightdat)
\end{Sinput}
\begin{Soutput}
[1] 194
\end{Soutput}
\begin{Sinput}
## summary of data
unique(sightdat$E)
\end{Sinput}
\begin{Soutput}
[1] 1
\end{Soutput}
\begin{Sinput}
unique(sightdat$Year)
\end{Sinput}
\begin{Soutput}
 [1] 1989 1987 1999 1990 1988 1986 2006 1992 2000 1998 2003 1993
\end{Soutput}
\begin{Sinput}
range(sightdat$PD)
\end{Sinput}
\begin{Soutput}
[1]  0.00 16.67
\end{Soutput}
\begin{Sinput}
range(sightdat$GS)
\end{Sinput}
\begin{Soutput}
[1] 1.15 9.60
\end{Soutput}
\end{Schunk}



\begin{Schunk}
\begin{Sinput}
par(mfrow = c(1, 2))
hist(sightdat$GS)  #, main ='histograme of group size')
hist(sightdat$PD)  #, main ='histograme of PD')
\end{Sinput}


{\centering \includegraphics[width=.80\linewidth]{/Users/joyce/Documents/yuan/INLASPDEPDRA/bluewhales/plots/BW_histSightLTmodeOnly} 

}

\end{Schunk}



\subsection{Problem with the effort data}

\begin{Schunk}
\begin{Sinput}
# ################ ### effort data for line transect locations
# efforig = read.table(file=paste(datadir, 'Eff86_06.csv', sep=''),
# header=T,sep=',' ,colClasses='numeric') head(efforig) ## get rid
# of the faulty entries in the effort datasets efforig =
# efforig[-which(efforig$lon> -75),] # ## understand how
# duplicate() works # tt = matrix(data=c(1:12), nrow =6, ncol =2) #
# tt[2,]=tt[1,] # tt[6,]=tt[1,] # tt # anyDuplicated(tt, MARGIN=1)
# # duplicated(tt, MARGIN=1) ## it should be duplicate the entire
# row not just lon or lat
# ########################################## ## duplicate function
# won't work for my case due to the complcated NAs in the data
# allID.NAeff = which(is.na(efforig$year), arr.ind=T)
# allID.NAeff=allID.NAeff[-1] head(allID.NAeff)
# duplicatedID.withNAs = NULL for(idx.LTsegment in
# c(2:length(allID.NAeff))) { IDstart =
# allID.NAeff[idx.LTsegment-1]+1 IDend =
# allID.NAeff[idx.LTsegment]-1 p0lonlat = c(efforig[IDstart,
# c('lon', 'lat')]) p1lonlat = c(efforig[IDend, c('lon', 'lat')])
# L=rdist.earth(x1=t(as.numeric(p0lonlat)),
# x2=t(as.numeric(p1lonlat)), miles = FALSE)
# if(L<1e-3){duplicatedID.withNAs =
# c(duplicatedID.withNAs,c((IDstart-1):IDend))} }
# length(duplicatedID.withNAs)## 975 duplicated rows effNoDuplicate
# = efforig[-duplicatedID.withNAs,] dim(effNoDuplicate)
# effNoDuplicate[1:50,] save(effNoDuplicate, file=paste(datadir,
# 'effNoDuplicate.Rdata',sep=''))
\end{Sinput}
\end{Schunk}


The above code gets rid of the duplicated rows in the effort data, and there is some complilcation in this process due to the NAs which are used in the original dataset to note the start and end of transect segments. Because of these NAs, I cannot use the function dumplicate(), and a loop has to be used. 

There are further errors in the effort data, and the related datails are given in an email to Tim. I cannot deal with all the issues as there are so many. So I will just get rid of the transect segments that are longer than 200km. 


\begin{figure}[!h]
\centering
% \begin{tabular}{cc}
\includegraphics[width=.66\textwidth]{histTransectLength.pdf}
% \includegraphics[width=.5\textwidth]{intgridonSpherelonlat.pdf}
% \end{tabular}
\caption{The histogram of the length of transect segments that are less than 200 km.}
\end{figure}

\begin{Schunk}
\begin{Sinput}
# efforig = read.table(file=paste(datadir, 'Eff86_06.csv', sep=''),
# header=T,sep=',' ,colClasses='numeric')
load(file = paste(datadir, "effNoDuplicate.Rdata", sep = ""))
eff = effNoDuplicate
############################################# load Bnd data The STAR boundary (black lines) apply to data from
############################################# 1998-2006.
boundSTART = read.table(paste(datadir, "BoundSTAR.dat", sep = ""), 
    header = F, skip = 1)
colnames(boundSTART) = c("lat", "lon")
head(boundSTART)
\end{Sinput}
\begin{Soutput}
    lat    lon
1 32.59 -117.5
2 32.63 -117.8
3 31.13 -118.6
4 30.54 -121.9
5 18.00 -128.0
6 10.00 -153.0
\end{Soutput}
\begin{Sinput}
range(boundSTART[, "lon"])
\end{Sinput}
\begin{Soutput}
[1] -153.0  -77.1
\end{Soutput}
\begin{Sinput}
## part of the boundary is the coastline
coast = read.table(paste(datadir, "AreaSTAR2.dat", sep = ""), sep = ",", 
    colClasses = "numeric", comment.char = "*", col.names = c("lat", 
        "lon"))
## original dataset is not numberic
coast$lat = as.numeric(as.character(coast$lat))
coast$lon = as.numeric(as.character(coast$lon))
## plot the sighting with effort&Bnd quartz()
plot(boundSTART[, "lon"], boundSTART[, "lat"], ylim = c(-30, 50), xlim = c(-160, 
    -70), type = "l", xlab = "longitude", ylab = "latitude", main = "2006 ETP with log(GS)")
lines(eff$lon, eff$lat, type = "l", col = "blue")

lines(coast[, "lon"], coast[, "lat"], type = "l", col = "red")
points(sightdat$Long, sightdat$Lat, col = "black", cex = log(sightdat$GS)/2)
## pch=15 for filled solid circle
\end{Sinput}


{\centering \includegraphics[width=.80\linewidth]{/Users/joyce/Documents/yuan/INLASPDEPDRA/bluewhales/plots/BWplot2006withEffortallyrs} 

}

\end{Schunk}


\begin{Schunk}
\begin{Sinput}
install.packages("fields")
\end{Sinput}
\begin{Soutput}
Error: trying to use CRAN without setting a mirror
\end{Soutput}
\begin{Sinput}
library(fields)
load(file = paste(resultdir, "effNo200plus_nodup.Rdata", sep = ""))
## have checked that effNo200plus has no LT longer than 200km
eff = effNo200plus
# effNo200plus has no duplicated entries and no 200plus LT
# ============================= ## length of the 1st LT segment L1
# =rdist.earth(x1=t(as.numeric(eff[2,c('lon', 'lat')])),
# x2=t(as.numeric(eff[3,c('lon', 'lat')])), miles = FALSE) IDna =
# which(is.na(eff$year), arr.ind=T) IDna = IDna[-1]## loop starts
# from the 2nd LT segment head(IDna) lengthOfAllLTsegments = L1
# for(idx.LTsegment in c(2:length(IDna))) { IDstart =
# IDna[idx.LTsegment-1]+1 IDend = IDna[idx.LTsegment]-1 p0lonlat =
# c(eff[IDstart, c('lon', 'lat')]) p1lonlat = c(eff[IDend, c('lon',
# 'lat')]) L=rdist.earth(x1=t(as.numeric(p0lonlat)),
# x2=t(as.numeric(p1lonlat)), miles = FALSE) lengthOfAllLTsegments
# = c(lengthOfAllLTsegments, L) } save(lengthOfAllLTsegments,
# file=paste(resultdir, 'lengthOfAllLTsegments.Rdata',sep=''))
# which(is.na(lengthOfAllLTsegments), arr.ind=T)
# range(na.omit(lengthOfAllLTsegments)) ID200plus =
# which(lengthOfAllLTsegments>200, arr.ind=T)

##### obtain the original rowID for LT longer than 200km IDna =
##### which(is.na(eff$year), arr.ind=T) IDna = IDna[-1]## loop starts
##### from the 2nd LT segment head(IDna) IDlength200plus = NULL
##### for(idx.LTsegment in c(2:length(IDna))) { IDstart =
##### IDna[idx.LTsegment-1]+1 IDend = IDna[idx.LTsegment]-1 p0lonlat =
##### c(eff[IDstart, c('lon', 'lat')]) p1lonlat = c(eff[IDend, c('lon',
##### 'lat')]) L=rdist.earth(x1=t(as.numeric(p0lonlat)),
##### x2=t(as.numeric(p1lonlat)), miles = FALSE) if(L>200){
##### IDlength200plus= c(IDlength200plus,c((IDstart-1):IDend))} }
##### save(IDlength200plus, file=paste(resultdir,
##### 'IDlength200plus.Rdata',sep='')) length(IDlength200plus)
##### head(IDlength200plus) # IDend=1866 # IDstart=1865 # p0lonlat =
##### c(eff[IDstart, c('lon', 'lat')]) # p1lonlat = c(eff[IDend,
##### c('lon', 'lat')]) # L=rdist.earth(x1=t(as.numeric(p0lonlat)),
##### x2=t(as.numeric(p1lonlat)), miles = FALSE) effNo200plus =
##### eff[-IDlength200plus,] save(effNo200plus, file=paste(resultdir,
##### 'effNo200plus_nodup.Rdata',sep=''))
\end{Sinput}
\end{Schunk}




\subsection{Preliminary analysis for the detection function}

We start with truncation distance $w=6km$. We fit a half-normal detection function to the PD distances. 

\begin{Schunk}
\begin{Sinput}
sightdat = sightdat[sightdat$Bf <= 5, ]
library(Distance)
\end{Sinput}
\begin{Soutput}
Loading required package: mrds
This is mrds 2.1.6
Built: R 3.0.2; ; 2014-06-11 06:27:08 UTC; unix
\end{Soutput}
\begin{Sinput}
xPD = data.frame(distance = sightdat$PD)
mod1 <- ds(xPD, truncation = 6)
\end{Sinput}
\begin{Soutput}
Starting AIC adjustment term selection.
Fitting half-normal key function
AIC= 586.248
Fitting half-normal key function with cosine(2) adjustments
AIC= 582.603
Fitting half-normal key function with cosine(2,3) adjustments
AIC= 582.483
No survey area information supplied, only estimating detection function.
\end{Soutput}
\begin{Sinput}
mod2 <- ds(xPD, truncation = 6, adjustment = NULL)
\end{Sinput}
\begin{Soutput}
Fitting half-normal key function
AIC= 586.248
No survey area information supplied, only estimating detection function.
\end{Soutput}
\begin{Sinput}
par(mfrow = c(1, 2))
plot(mod1)
plot(mod2, main = "without adjustment")
\end{Sinput}


{\centering \includegraphics[width=.80\linewidth]{/Users/joyce/Documents/yuan/INLASPDEPDRA/bluewhales/plots/checkhalfnormDetect} 

}

\end{Schunk}




\section{The log-likelihood of line tranect data as a filtered point process(FPP)}
Following the log-likelihood given by (3) in \citet{Johnson+al:2010}, we give the log-likelihood of line transect survey data with half-normal detection function. 
We use $\mathcal{C}_k$ to denote the area sampled by the $k$th transect line, where $k=1, 2, \ldots, K$. $n_k$ denotes the number of animals sighted on the $k$th transect line. $ \bm{x}(\bm{s})$ denotes the covariate vector for site $\bm{s}$ and $\bm{\beta}$ is the corresponding parameter vector. $\omega(\bm{s})$ is the realization of the GMRF at site $\bm{s}$. $z_k(\bm{s}_i)$ denotes the perpendicular distance from $\bm{s}_i$ to the $k$th transect line. Then the log-likelihood of line transect survey data is 
\be
l_{LT}= \sum_{k=1}^K\sum_{i=1}^{n_k} \left[  \bm{x}(\bm{s}_i) ^T \bm{\beta} +\omega(\bm{s}_i)  -\frac{1}{2}\left(\frac{z_k(\bm{s}_i)}{\sigma_g} \right)^2\right] - \sum_{k=1}^K\int_{\mathcal{C}_k}\exp\left[\bm{x}(\bm{u})^T \bm{\beta} +\omega(\bm{u})  -\frac{1}{2}\left(\frac{z_k(\bm{u})}{\sigma_g} \right)^ 2\right] d \bm{u}
\plab{eq:filterPPP}
\ee
which consists of two parts: the first is for evaluating the density surface of the filtered point process at the observed locations, and the second is the integral of the density function over the sample area. 





We approximated the integration part numerically by 

  evaluate the field at the integration points

scheme designed on tangent planes to the sphere. 

% \bes
% \int_{\mathcal{A}\mathcal{S}(\bm{s})}\exp\left[   \bm{x}(\bm{u})^T \bm{\beta} +\omega(\bm{u})  -\frac{1}{2}\left(\frac{x^{pd}(\bm{u})}{\sigma_g} \right)^ 2\right] d \bm{u}  =   \int_{\mathcal{C}}
% \exp\left[   \bm{x}(\bm{u})^T \bm{\beta} +\omega(\bm{u})  -\frac{1}{2}\left(\frac{x^{pd}(\bm{u})}{\sigma_g} \right)^ 2\right] d \bm{u} 
% \ees



\section{The integration steps for each transect segment}
Here I do not use the term transect line, as in practice, each whole transect line consists of several transect segments, as the ship has to stop for some reasons. 

The effort dataset uses NAs to separate different transect segments. Let $p_0$ denote the starting point of a transect segment, and $p_1$ denote the finishing point of a transect segment. The earth is considered as a sphere in a Euclidean space 
$\mathcal{R}^3$ with the centre of the earth being origin, denoted by $\mathcal{O}$. Let $\overrightarrow{p_0p_1}$ denote the vector starting from $p_0$ and pointing towards $p_1$.



It is very unlikely that transect lines are perfectly on the east-to-west or north-to-south drection, for which the boundary of transect strips is easy to specify. In the longitude and latitude system, it is difficult to apply geometric operations to find vectors that are perpendicular to $\overrightarrow{p_0p_1}$ on each side of the transect line, and loction the points that are 10 km away from $p_0$ along the perpendicular direction on each side. 

So first we transform the longitude and latitude system into $\mathcal{R}^3$ so that geometric operations become applicable. Then we construct local coordinate system for each $\overrightarrow{p_0p_1}$ with $p_0$ as the new origin, and design the integration on the tangent plane defined by $\overrightarrow{p_0p_1}$ and a unit vector that is perpendicular to $\overrightarrow{p_0p_1}$. For simplicity, we use $\bm{v}_1$ to denote $\overrightarrow{p_0p_1}$, and $\bm{v}_3$ to denoted the direction that is perpendicular to $\overrightarrow{\bm{w}_0}$. Following the righthand rule, $v_1$ is the 3rd coordinate which is perpendicular to the tangent plane, denoted by $\bm{v}_1$. 


The advange of the $(\bm{v}_1\bm{v}_2, \bm{v}_3)$ system with $p_0$ as origin is that $\bm{v}_3$ and $-\bm{v}_3$ give 90 degree counterclockwise and clockwise to transect lines, respectively. Furthermore, if the truncation distance is 10km and transect segment is 39km, then the four corners of the transect rectangle can be simplied specified by $(0,0,10)$, $(0, 0, -10)$, $(0, 39, 10)$ and $(0, 39, -10)$, on top of which the integration grid is then designed to approximate the point process likelihood. (These transects regions are very small, so the Euclidean distance in the tangent plane is almost he same as the spherical distance.  Note that both of those distances are not precisely the same as the true
distance metric anyway. For now, we use the mean radius of the earch and ignore the fact that the earth radius varies by latitude.)

The integatrion points are the centers of each cell in an equally spaced grid on the transect tectangle, and the size of each grid cell is viewed as the weight for each integration point. We transform these integration points from $(\bm{v}_1\bm{v}_2, \bm{v}_3)$ back to longtitude and latitude, but keep the weights in the tangent plane system as the effect of curvation on the change of the area of transect strip is ignorable given the small size of transect strips in comparison of the earth.( Finn pointed out that at some point a more exact formula should be written down, if only to prove that it's not
needed).

\bi
\item Step1: tranform to $\mathcal{R}^3$ \\
For any point $\bm{p}$ with longitude and latitude, $long_p$ and $lat_p$, we use the following tranformation to find its coordinates $(px, py, pz)$ in $\mathcal{R}^3$
\be
px &=& R cos(long_p)cos(lat_p)\\
py &=& R cos(lat_p) sin(long_p)\\
pz &=& R sin(lat_p)
\ee

\item Step2: for any $p_0$ and $p_1$, calculat the tangent plane system\\
The following calculation should be down in the shown sequence 
\be
\bm{v}_1 &=& \bm{p}_0\biggr/\lVert \bm{p}_0 \rVert \\
\bm{v}'_3 &=& \bm{v}_1 \times (\bm{p}_1 - \bm{p}_0); \bm{v}_3 = \bm{v}'_3/ \vnorm{\bm{v}'_3 }\\
\bm{v}_2&=&\bm{v}_3 \times \bm{v}_1
\ee

\item Step 3 : Define integration grid on the tangent plane on the $(\bm{v}_1\bm{v}_2, \bm{v}_3)$ system\\

Let $R$ denote the rotation matrix which gives the coordiates with respect to $(\bm{v}_1\bm{v}_2, \bm{v}_3)$
\be
\bm{R} = \begin{bmatrix}
       v_{11} & v_{12} & v_{13}           \\[0.3em]
       v_{21} & v_{22} & v_{23}           \\[0.3em]
       v_{31} & v_{32} & v_{33}
     \end{bmatrix}
\ee
where $\bm{v}_1 =(v_{11}, v_{12}, v_{13})^T$. 

For any vector $\bm{v}$ (a column vector) in $\mathcal{R}^3$, we tranform $\bm{v}$ in the tangent plane system by using the totation matrix $\bm{R}$, and the new vector is 
\be
\bm{v}' = \bm{R} \bm{v}
\ee

Note that $\bm{R}$ is an orthogonal matrix and $\bm{R}^{-1} = \bm{R}^T$, for any $\bm{v}'$ in $(\bm{v}_1\bm{v}_2, \bm{v}_3)$ system, we simply tranform it back to $\mathcal{R}^3$ by 
\be
\bm{v} =\bm{R}^T \bm{v}'
\ee
where $\bm{p}=(px,py, pz)^T$.

Vectors are simpler to transform than points as vectors represent directions in space whereas points represent locations in space. The direction is not affected by change of origin of coordinate system, however the points are. When transforming a point into a new coordinate sysmte, we need to incorporate the information about the change of origin. 

For any point $\bm{p}=(px,py, pz)^T$ in $\mathcal{R}^3$, if we use $\bm{p}_0$ as the new origin in the tangent plane system, then the coordinates of $\bm{p}$ after tranformation is 
\be
\bm{p}' = \bm{R} (\bm{p}-\bm{p}_0)
\ee

\item Step 4: design a grid on plane given by $(v2,v3)$\\

\item Step 5:  transform back the points on grid to (lon,lat) and evaluate the PP.
\ei

the mean earth radius = 6371 km 

\begin{figure}[H]
\centering
\begin{tabular}{cc}
\includegraphics[width=.5\textwidth]{intgridonTangentPlane.pdf}&
\includegraphics[width=.5\textwidth]{intgridonSpherelonlat.pdf}
\end{tabular}
\caption{Design integration grid on tangent plane and then tranform to sphere: the integration points and weights are all specified on the tangent plane, and the integration points are then transformed to the longitute and latitute on the sphere, while the integration weights stay the same as the curvation effect is ignored here.}
\end{figure}







\section{Design the integration on the tangent plan}
% 
% <<rotateVector>>=
% porig = matrix(as.numeric(eff[5, c("lon", "lat")]), nrow= 2)
% xorig = porig[1]; yorig = porig[2]
% pend = matrix(as.numeric(eff[6, c("lon", "lat")]), nrow=2)
% xend = pend[1]; yend = pend[2]
% # rotmat= function(theta)
% # { x11 = cos(theta)
% #   x12 = -sin(theta)
% #   x21 = sin(theta)
% #   x22 = cos(theta)
% #   mat = matrix(data=c(x11, x12, x21, x22), 2, 2, byrow=T)
% #   return(mat)
% # }
% # rotmat(pi/2)
% rot90counterclock = matrix(c(0, -1, 1, 0), 2, 2, byrow=T)
% rot90clock = matrix(c(0, 1,-1, 0), 2, 2, byrow=T)
% 
% 
% v = pend-porig
% vn = v/norm(v)*5
% 
% prot = rot90counterclock%*%v + porig
% prot1 = rot90counterclock%*%vn + porig
% prot2 = rot90clock%*%vn + porig
% 
% 
% quartz()
% par(pty="s") 
% plot(prot[1], prot[2], xlim = c(-122, -110), col="red")
% points(prot1[1], prot1[2], col="blue")
% points(porig[1], porig[2], col="black")
% points(pend[1], pend[2], col="green")
% arrows(x0=xorig, y0=yorig, x1=xend, y1=yend, col="green")
% arrows(x0=xorig, y0=yorig, x1 = prot[1], y1=prot[2], col="red")
% arrows(x0=xorig, y0=yorig, x1 = prot1[1], y1=prot1[2], col="blue")
% arrows(x0=xorig, y0=yorig, x1 = prot2[1], y1=prot2[2], col="yellow")
% 
% ## this fun calculates the angle between vectors a and b
% thetacheck.pi = function(a,b){theta = acos( sum(a*b) / ( sqrt(sum(a * a)) * sqrt(sum(b * b)) ) )
% return(theta/pi)}
% # ## calculate the angle between prot-porig, and v= pend - porig
% # ## here we rotate wrt porig 
% # thetacheck.pi(a=prot-porig, b=v)
% # ## it is 0.5*pi = 90 degree
% # ## the ratio of the x-axes and y-axes messes up with the 90 degree angle. 
% # library(fields)
% # x1=t(porig) 
% # x2 = t(pend)
% # rdist.earth(x1, x2, miles = FALSE, R = NULL)
% # 
% @
% 
% <<geodistCode>>=
% # Convert degrees to radians
% deg2rad <- function(deg) return(deg*pi/180)
% 
% # Calculates the geodesic distance between two points specified by
% # radian latitude/longitude using the Haversine formula
% gcd.hf <- function(long1, lat1, long2, lat2) {
% R <- 6371 # Earth mean radius [km]
% delta.long <- (long2 - long1)
% delta.lat <- (lat2 - lat1)
% a <- sin(delta.lat/2)^2 + cos(lat1) * cos(lat2) * sin(delta.long/2)^2
% c <- 2 * asin(min(1,sqrt(a)))
% d = R * c
% return(d) # Distance in km
% }
% 
% # Fxn to calculate matrix of distances between each two sites
% CalcDists <- function(latlongs) {
% name <- list(rownames(latlongs), rownames(latlongs))
% n <- nrow(latlongs)
% z <- matrix(0, n, n, dimnames = name)
% for (i in 1:n) {
% for (j in 1:n) z[i, j] <- gcd.hf(long1 = latlongs[i, 1],
% lat1 = latlongs[i, 2], long2 = latlongs[j, 1], lat2 = latlongs[j,2])
% }
% z <- as.dist(z)
% return(z)
% }
% @



% <<plot3D, webgl=TRUE>>=
% library(rgl)
% ### here is my 1st try of my data
% mydat = cbind(v1, v2, v3)
% 
% open3d()
%   x <- mydat[1,]
%   y <- mydat[2,]
%   z <- mydat[3,]
%   plot3d(x, y, z, col=rainbow(ncol(mydat)))
% segments3d(rbind(v1,v2), col="red")
% segments3d(rbind(v2,v3), col="green")
% 
% v0 =c(0,0,0)
% 
% library(rgl)
% coord1  = rbind(v0, v1)
% coord2 = rbind(v0, v2)
% coord3 = rbind(v0, v3)
% plot3d(coord2,type="l",col="red",xlim=c(0,3),ylim=c(0,3),zlim=c(0,3))
% plot3d(coord1,type="l",add=TRUE,col="blue")
% plot3d(coord3,type="l",add=TRUE,col="green")
% # This writes a copy into temporary directory 'webGL', and then displays it
% browseURL(paste("file://", writeWebGL(dir=file.path(tempdir(), "webGL"), 
%           width=500), sep=""))
% @

% # library(rgl)
% # x <- sort(rnorm(1000))
% # y <- rnorm(1000)
% # z <- rnorm(1000) + atan2(x,y)
% # plot3d(x, y, z, col=rainbow(1000))
% # text3d(x, y, z, text=c(rep("", 990), LETTERS[1:10]))
% # writeWebGL()

% more examples can be found on 
% http://stackoverflow.com/questions/3979240/r-plotting-a-3d-surface-from-x-y-z
% 
% <<plotUnitSphere2D>>=
% R =1
% lon = runif(1000, -1, 1)
% lat = runif(1000, 0, 1)
% 
% 
% dat = expand.grid(Lon = lon, Lat = lat)
% 
% dat$x0 = signif(R*cos(dat$Lon*pi)*cos(dat$Lat*pi),3)##has to keep sigfig limted. ow overflow of integers
% dat$y0 = signif(R*cos(dat$Lat*pi)*sin(dat$Lon*pi),3)
% dat$z0 = signif(R*sin(dat$Lat*pi),3)
% range(dat$x0)
% range(dat$y0)
% range(dat$z0)
% 
% plot3d(dat[,-c(1,2)])
% 
% 
% quartz()
% wireframe(z0~x0+y0, dat[,-c(1,2)],shade = T, drape=T,
%           aspect = c(3, 2), type="b",
% #           aspect=c(1,1), ## taio of the panel (see xyplot for details)
%           light.source = c(10,10,10), ##ender the surface as being illuminated by a light source (no shadows though)
%           #main = "",
%           scales = list(z.ticks=5,arrows=F, col="blue", font=10, tck=0.5),
%           screen = list(z = 40, x = -75, y = 0)) 
% 
% quartz()
% wireframe(z0~x0+y0, dat[,-c(1,2)],drape = TRUE, perspective = FALSE, aspect = c(3,2), colorkey = TRUE)
% # library(rgl)
% # Data <- expand.grid(x=seq(0,10),y=seq(0,10))
% # Data$z <- Data$x^2+Data$y^2
% # plot3d(Data)
% # library(lattice)
% # wireframe(z~x+y,Data)
% @
% 







\begin{Schunk}
\begin{Sinput}
## detail step functions are in file 'RfunsIntegrationDesign.r'
range(na.omit(eff$lon))
\end{Sinput}
\begin{Soutput}
[1] -152.99  -77.26
\end{Soutput}
\begin{Sinput}
range(na.omit(eff$lat))
\end{Sinput}
\begin{Soutput}
[1] -18.00  32.58
\end{Soutput}
\begin{Sinput}

## step1: tranform from long&lat to XYZ using mean radius
p0lonlat = c(eff[5, c("lon", "lat")])
p0 = tranformLongLatToXYZ(long = p0lonlat$lon, lat = p0lonlat$lat, 
    R = 6371)

p1lonlat = c(eff[6, c("lon", "lat")])
p1 = tranformLongLatToXYZ(long = p1lonlat$lon, lat = p1lonlat$lat, 
    R = 6371)

# Radiants = degree*pi/180 degree = radiant*180/pi
cos(0)
\end{Sinput}
\begin{Soutput}
[1] 1
\end{Soutput}
\begin{Sinput}
cos(90/180 * pi)
\end{Sinput}
\begin{Soutput}
[1] 6.123e-17
\end{Soutput}
\begin{Sinput}
## note that cosine in R works on degree instand of radiant
cos(29.7667/180 * pi)
\end{Sinput}
\begin{Soutput}
[1] 0.8681
\end{Soutput}
\end{Schunk}




% 
% The alternative way to give the axes of the new system, use -p0 instead of p0 
% <<Step1AlternativeFindTangentPlanV1v2v3>>=
% v1 = - p0; v1 = v1/normvec(v1) ## pc is the center of the sphere 
% v3 = cross(v1, p1- p0); v3 = v3/normvec(v3)
% v2 = cross(v3, v1)
% v1;v2;v3
% ## check orthogonal 
% crossprod(v1, v2)
% crossprod(v2, v3)
% crossprod(v3, v1)
% @


All the code to produce integration matrix can be found in "rfunIntegrationDesign.R". 

Which new orgin to use, $v1 = p0$ or $v1 = -p0$, does not matter for the new coordinates in the new system. Here we use p0 as the new origin. I have checked my code by tranforming back and forth and it gives consistent results. As long as p0 is used as the origin in the new coordinate system, it does matter v1 = p0 or v1 = -p0. 


Note the simplicity resulting from using (v1, v2, v3) system. Summarise these steps in one function and also another one to transform back 



The configiration of the integration grid: 
\bi 
\item Along the direction perpendicular to the transect line, the cell size is chosen to be be divisors of the truncation distance $w$. For the most sparse grid we use the cell size equal to $w$.
\item It is slightly more complicated design for the integration cell size along the transect direction. As the length of transect segments vaies from 0.01km to 200 km (for now I exlucde all the segments that are longer than 200 km), we deal with the segments differently depending on their length 
\bi 
\item if the length of a segment is no longer than dLT (the cell size along line transect direction), then we simply treat this segment as one grid cell and the integration points along the middle of the transect line. 
\item if the length of a segment is longer than dLT, then we divide the transect segment by dLT. Let $nLT$ denote the number of cells along the transect direction. If the reminder of length(segment) divided by dLT is larger than 0.5, then $nLT = round(length(segment)/dLT)$, otherwise,  $nLT = round(length(segment)/dLT)-1$
\ei 
\item Note that not all integration cells have the same weight, though most of them have the size $dLT\times dPD$
\ei 


\begin{Schunk}
\begin{Sinput}
## to check the code by using the 1st point in intgrid
## lonlatTopIntGrid.onsphere=convert.fromXYZtoLongLat(pxyz=topIntGrid.onsphere,R=6371)
## lonlatTopIntGrid.onsphere ???? equally spaced grid, the weight is
## just dLT*dPD

## transfrom from xyz to long&lat???  lat=atan2(z,sqrt(x*x+y*y))
## long=atan2(y,x) Given a point location p and normalised transect
## direction v, the perpendicular CCW (counterclockwise) vector is
## given by the cross-product $w = p \times v$.  (p,v,w) then forms
## the basis of a local coordinate system, with (1,a,b) being the
## coordinates of a point in the tangent plane.  This can then be
## transformed back into longitude latitude by first normalising the
## point to have unit length (so it's on the sphere, and then
## computing the long-lat mapping.  The mappings can be done with ##
## the following funs simply provide mapping between R3 and sphere
## long&lat system
onthesphere = inla.mesh.map(loc = intgrid.lonlat.try1, projection = "longlat")
\end{Sinput}
\begin{Soutput}
Error: object 'intgrid.lonlat.try1' not found
\end{Soutput}
\begin{Sinput}
lonlat = inla.mesh.map(onthesphere, projection = "longlat", inverse = FALSE)
\end{Sinput}
\begin{Soutput}
Error: object 'onthesphere' not found
\end{Soutput}
\begin{Sinput}
str(onthesphere)
\end{Sinput}
\begin{Soutput}
Error: object 'onthesphere' not found
\end{Soutput}
\begin{Sinput}
str(lonlat)
\end{Sinput}
\begin{Soutput}
Error: object 'lonlat' not found
\end{Soutput}
\end{Schunk}





% 
% <<ObtainIntGridLonLat>>=
% p0lonlat = c(eff[2, c("lon", "lat")])
% p1lonlat = c(eff[3, c("lon", "lat")])
% w=8
% dLT=2.5
% dPD=2
% ### try the fun on the 1st segment from effort data 
% ### detail about fun "designintegration.oneLTsegement" in the related Rfun source file 
% intgridlonlat.1stLTsegment = designintegration.oneLTsegement(p0lonlat, p1lonlat, w, dLT, dPD)
% summary(intgridlonlat.1stLTsegmemt)
% head(intgridlonlat.1stLTsegment$intgridR3)
% head(intgridlonlat.1stLTsegment$intgridlonlat)
% @
% 
% 


\section{Stack together: integration points}
In future coding, A.pp, e.pp and y.pp should be kept together, as any change in one of them, the rest should be changed accordingly.
\begin{Schunk}
\begin{Sinput}
load(file = paste(datadir, "mesh_stitchInterior.Rdata", sep = ""))
plot(boundSTART[, "lon"], boundSTART[, "lat"], ylim = c(-30, 50), xlim = c(-160, 
    -70), type = "l", xlab = "longitude", ylab = "latitude", main = "2006 ETP with log(GS)")
lines(eff$lon, eff$lat, type = "l", col = "blue")
lines(coast[, "lon"], coast[, "lat"], type = "l", col = "red")
points(sightdat$Long, sightdat$Lat, col = "black", cex = log(sightdat$GS)/2)
plot(mesh, add = T)
\end{Sinput}


{\centering \includegraphics[width=\maxwidth]{/Users/joyce/Documents/yuan/INLASPDEPDRA/bluewhales/plots/plotsightWithMesh} 

}

\end{Schunk}


\begin{Schunk}
\begin{Sinput}
# nv = mesh$n
spde = inla.spde2.matern(mesh = mesh, alpha = 2)
spde$n.spde
\end{Sinput}
\begin{Soutput}
[1] 443
\end{Soutput}
\end{Schunk}



\begin{Schunk}
\begin{Sinput}
head(sightdat)
\end{Sinput}
\begin{Soutput}
  Sp1 Sp2 Sp3 Sp4 Cruz Sght E Obs Year Month Day Time    Lat
1  75  NA  NA  NA 1267    1 1   7 1989    11  11  639 10.619
2  75  NA  NA  NA 1081    1 1  51 1987     8  10  816 26.513
3  75  NA  NA  NA 1268    1 1  55 1989     9  24  826 -1.256
5  75  NA  NA  NA 1614    1 1 198 1999     7  28 1622 31.731
6  75  NA  NA  NA 1370    1 1  55 1990    12   2  658 21.641
7  75  NA  NA  NA 1081    2 1  64 1987    10  24 1030  9.918
     Long   GS TotGS   PD Bf SH  SD RF HS VS WSp WDi Cue Me Ph Bi
1  -98.95 1.16  1.16 1.37  2 -1  -1  1  1  3  -1  -1   6  4 -1  0
2 -116.18 2.32  2.32 0.78  2 -1  -1  1 -1 -1  -1  -1   6  4 -1  0
3  -91.31 2.32  2.32 1.59  4 -1  -1  2 -1 -1  -1  -1   6  5 -1  0
5 -116.94 2.32  2.32 0.93  3  4 302  1  3  2  13 323   6  4  0  0
6 -115.47 2.76  2.76 0.16  5 -1  -1  1  4  3  -1  -1   6  5 -1  0
7  -96.03 2.65  2.65 1.65  3 -1  -1  1 -1 -1  -1  -1   6  4 -1  0
  Mx Crs  SST  Vis Angl Retcl RadD InitID MSp
1  0  65 27.2 -1.9   21   1.0 3.84     -1  -1
2  0 154 21.7 -1.9   20   2.4 2.27     -1  -1
3  0 120 19.4 -1.9   35  -1.0 2.78     -1  -1
5  0 156 -1.0 11.1  346   1.0 3.83     -1  -1
6  0 343 -1.0 -1.9  350  -1.0 0.93     -1  -1
7  0 203 27.8 -1.9   20   0.6 4.84     -1  -1
\end{Soutput}
\begin{Sinput}
nrow(sightdat)
\end{Sinput}
\begin{Soutput}
[1] 194
\end{Soutput}
\begin{Sinput}
sightdatTrunc = sightdat[sightdat$PD <= 6, ]
nrow(sightdatTrunc)
\end{Sinput}
\begin{Soutput}
[1] 181
\end{Soutput}
\begin{Sinput}
sightloc = cbind(lon = sightdatTrunc$Long, lat = sightdatTrunc$Lat)
## ndata is the no. of sightings (truncated)
ndata = nrow(sightloc)
## 194 sighting (LT mode) for BW over 12 years
length(unique(na.omit(sightdatTrunc$Year)))
\end{Sinput}
\begin{Soutput}
[1] 12
\end{Soutput}
\begin{Sinput}
## matrix for evaluating likelihood at the sighting locations
locmat = inla.spde.make.A(mesh, loc = sightloc)
dim(locmat)
\end{Sinput}
\begin{Soutput}
[1] 181 443
\end{Soutput}
\begin{Sinput}
############ load the integration points matrix
version = "_v9"
load(paste(resultdir, "IntPointMatrixLonLat", version, ".Rdata", sep = ""))
nrow(IntPointMatrixLonLat)
\end{Sinput}
\begin{Soutput}
[1] 140328
\end{Soutput}
\begin{Sinput}
head(IntPointMatrixLonLat)
\end{Sinput}
\begin{Soutput}
        lon   lat weight
[1,] -115.8 29.72     36
[2,] -115.8 29.63     36
[3,] -115.8 29.72     36
[4,] -115.8 29.64     36
[5,] -115.9 29.71     36
[6,] -115.9 29.63     36
\end{Soutput}
\begin{Sinput}
## load the v1v2v3 integration design matrix on v1v2v3
load(file = paste(resultdir, "IntMatrixv1v2v3List", version, ".Rdata", 
    sep = ""))
dPD = unique(IntMatrixv1v2v3List[[1]]$dPD)
## integration matrix
intmat = inla.spde.make.A(mesh, IntPointMatrixLonLat[, -3])
nInt = nrow(intmat)
## PD for the integtration points
xPDIntPoints = rep(dPD, nrow(IntPointMatrixLonLat))

############ combine locmat and intmat together
A.pp = rBind(intmat, locmat)
dim(A.pp)
\end{Sinput}
\begin{Soutput}
[1] 140509    443
\end{Soutput}
\begin{Sinput}
y.pp = rep(0:1, c(nInt, ndata))
length(y.pp)
\end{Sinput}
\begin{Soutput}
[1] 140509
\end{Soutput}
\begin{Sinput}
# , nInt is no. of integration points and n is number of
# observations
e.pp = c(IntPointMatrixLonLat[, "weight"], rep(0, ndata))
length(e.pp)
\end{Sinput}
\begin{Soutput}
[1] 140509
\end{Soutput}
\begin{Sinput}
######### the stack: without any covariates; stk.pp =
######### inla.stack(data=list(y=y.pp, e=e.pp), A=list(A.pp), tag='pp',
######### effects=list(i=1:spde$n.spde)) Your effects info is wrong. The
######### effect should index the latent model, not the integration points
######### (which from the point of view of inla are 'data'). the code
######### should be effects=list(i=1:spde$n.spde)
\end{Sinput}
\end{Schunk}


Note that I don't have the SST data for all the 12 years, therefore, I cannot incorporate the SST now. 
 
\begin{Schunk}
\begin{Sinput}
stk = inla.stack(data=list(y=y.pp, e = e.pp),
                A=list(A.pp,1), tag='fPP1',
                effects=list(list(i=1:spde$n.spde),
                            data.frame(Intercept=1,
                                     Lon = c(IntPointMatrixLonLat[,"lon"], sightloc[,"lon"]),
                                     Lat = c(IntPointMatrixLonLat[,"lat"], sightloc[,"lat"]),
                                             # SST = c(SSTonMesh, SSTonSightLoc),
                                             xPDmod =c(-xPDIntPoints^2/2,
                                                       -as.numeric(sightdatTrunc$PD)^2/2)
                                     #need to transform the xPD as a covariate into INLA.call
                                             )))
# formula for Flitered PP
formula.fpp = y~ -1+ Intercept + Lon +Lat + f(xPDmod, model="clinear", range = c(0, Inf)) 
                  + f(i, model=spde)
\end{Sinput}
\begin{Soutput}
Error: invalid argument to unary operator
\end{Soutput}
\begin{Sinput}
## have to run the code on INLA server ##
# result.fpp = inla(formula.fpp, family = "poisson",   data=inla.stack.data(stk),
#              control.predictor=list(A=inla.stack.A(stk)),
#              # the following line is necessary, the filtering component is treated as an iid random effect with fixed high precision (low variance)
#              control.family = list(hyper = list(prec = list(initial =log(1/0.01^2), 
#                                                             fixed=TRUE))),
#               E=inla.stack.data(stk)$e, inla.call="remote")
# 
# summary(result.fpp)
# 
# plot(result.fpp)
\end{Sinput}
\end{Schunk}


% Atilde= inla.stack.A(stk.pp)
% image(Atilde)
% # A=list(A.pp,1) has some zero columns (as there are triangles that cover no observed points)
% # Atilde is the A matrix that has excluded all those zero columns for the 1st block (the spde part)
% # from image(Atilde) you can see that there are two blocks of the matrix, 1st block is for the GMRF and the 2nd block is for the fixed effects 

   







% \section{Improved boundary and constraint handling in fmesher}
% 
% I've updated fmesher to handle boundary and interior constraint specifications much more cleanly, so that, for example, some common GIS data inconsistencies shouldn't break the mesh generation.
% The new code handles intersecting (including self-intersecting) boundaries. The resulting domain is defined by the region, if any, that all the specified boundaries agree are in the interior of the domain.
% 
% Essentially, this allows defining domains as the intersection between closed boundary curves, but certain kinds of combinations of open boundary curves segments can be combined and still generate a well-defined domain.
% 
% R code that previously worked should still generate the same results, unless they relied on the default cutoff=0; this has been changed to $1.0e-12$, which is a much more sensible MINIMUM numerical default.  In
% practice, it is often sensible to set cutoff MUCH higher.
% 
% R code that used to break fmesher by forcing it to generate an empty mesh or fall into an infinite loop due to boundary issues will now produce a proper mesh.  (Certain infinite loops due to other issues remain, but are nowadays extremely rare in practice.)
% 
% Example code for illustration (will only work after the package has
% been updated; please notify my immediately if you encounter problems
% with pre-existing R-code):
% <<IllustrateImprovedBnd>>=
% th=seq(0,2*pi,length=33)
% loc1=cbind(cos(th)-0.5,sin(th))
% loc2=cbind(cos(th)+0.5,sin(th));
% seg1=inla.mesh.segment(loc1,is.bnd=TRUE)
% seg2=inla.mesh.segment(loc2,is.bnd=TRUE)
% mesh = inla.mesh.create(
%    boundary=list(seg1,seg2),
%    refine=list(min.angle=30),
%    plot.delay=1)
% plot(mesh)
% 
% mesh2=inla.mesh.2d(boundary=list(seg1,seg2),max.edge=c(0.1,1),plot.delay=0)
% plot(mesh2)
% ## The "outer" layer in this example is cutting into the already
% ## refined "inner" layer; this situation could be improved, but that is
% ## non-trivial.
% ## Changing the input information and/using the new per-vertex quality
% ## option is easier.
% 
% ## Sphere:
% loc1s=inla.mesh.map(loc1*60,projection="longlat")
% loc2s=inla.mesh.map(loc2*60,projection="longlat")
% seg1s=inla.mesh.segment(loc1s,nrow(loc1s):1,is.bnd=TRUE)
% seg2s=inla.mesh.segment(loc2s,nrow(loc2s):1,is.bnd=TRUE)
% meshs = inla.mesh.create(
%    boundary=list(seg1s,seg2s),
%    refine=list(min.angle=30),
%    plot.delay=1)
% plot(meshs, rgl=TRUE) ## Hint: Remember to rotate the view!
% @
% \appendix 
% \subsection{email from Finn}
% \bi 
% \item
% Yes, you got it right.  And since each transect line observation region
% is to small to "see" the change in area measure due to the curvature,
% you can design the integration points and weights in the tangent space
% and simply transform the integration points back to the sphere without
% changing the integration weights. (Though at some point a more exact
% formula should be written down, if only to prove that it's not
% needed...)
% 
% 
% If "s" is some point in the observation region projected onto the
% tangent plane, then the can be written as
% \be
%    s = 1 p + a v + b w
% \ee
% for some a and b, i.e. (1,a,b) are the coordinates of s in the system
% (p,v,w).
% 
% Another projection than the one I described is given by perpendicular
% projection onto the tangent plane, in which one simply takes the point
% "s" on the sphere itself, and evaluates coordinate values (c,a,b),
% where $c\leq1$, and a and b will be almost the same as with the radial
% deformation I mentioned.  Both projections have names in the earch
% mapping literature that I've forgotten...
% 
% 
% 
% \item 
% 
% {\it  To get the system $(p, v, w)$, I need to consider p and v in $R^3$. I need to transform the long \&lat system for p and v into $R^3$ by
% \bes
% &&x = R*cos(lat)*cos(long)  \quad \mbox{R is the radius}\\
%  &&y = R*cos(lat)*sin(long)\\
% && z=R*sin(lat)\\
%  &&v= (p1-p0)/norm(p1-p0)
%  \ees
%  p can be any point on the transect line from p0 to p1
% }
% 
% Actually, it's slightly easier to construct v and w in the opposite order, by starting with p0 and p1 being two points on the transect line,
% on the sphere:
% 
% w = p0 cross (p1-p0), and normalise to unit length
% v = w cross p0, and normalise to unit length
% 
% after that, $(p0, v, w)$ is the basis you'll be working in.
% The v=(p1-p0) method wouldn't give a tangent vector at p0.
% 
% 
% { \it The integration grid is set up on the surface given by v and w. What I don't get is why it is (1, a, b), not (0, a, b). For any points on the tangent plan wrt to the (p,v,w) system, why it is always $1\times p$ for the p-axis.}
% 
% 
% We'll, it's a matter of taste...  By treating all points as embedded in $R^3$ and with origin at the centre of the sphere, all points in the tangent plane have first coordinate = 0.  
% 
% But that coordinate isn't actually used much...
% Also, you have to decide on which projection to use: either orthogonal projection onto the plane or radial projection to the plane. 
% 
% Both are simple, but the orthogonal projection is likely easier.
% 
% {\it I think I still need to get the transect polygon (w distance away from each side of the transect line) in the tangent space. Does this mean that in the $(p, v, w)$ system, I can simply use the Euclidean distance to find the polygons?}
% 
% Yes.  These transects regions are very small, so the Euclidean distance
% in the tangent plane is almost he same as the spherical distance.  Note
% that both of those distances are not precisely the same as the true
% distance metric anyway.
% 
% {\it Say you have a transect line perfectly following the direction from east to west, and it length is 39km, I need to find the northeast corner and the other 3 corners to define the integration grid.  As I don't have the perfect east to west direction for transect lines in practice, so I was thinking about rotating the transect line CCW and CW 90 degree to get  the corners of the transect strip.}
% 
% Yes, but that's precisely what is easy to do when using the tangent plane coordinate system; basically, working with longitudes and latitudes is almost never the best way, since simple geometric operations are much harder in long/lat than when treating the sphere as embedded into $R^3$ and constructing local coordinate systems.
% 
% 
% {\it The advantage of using (v, w) system is that the w and -w gives the CCW and CW directions I need on each side of the transect line. I simply need to incorporate the distance 10km along the directions w and -w.  Is it ok to use Euclidean distance on the tangent plane?}
% 
% 
% Precisely, that's the motivation for doing that construction.
% 
% You will of course need the radius of the earth, which varies with
% latitude (!) but I think we can safely ignore that non-stationarity
% here, and just use an average radius, or the equator radius.
% 
% Finn
% 
% 
% \item 
% > The advantage of using (v, w) system is that the w and -w gives the CCW
% > and CW directions I need on each side of the transect line. I simply
% > need to incorporate the distance 10km along the directions w and -w.  Is
% > it ok to use Euclidean distance on the tangent plane?
% 
% There will be a small bias due to the change in area measure when
% projecting onto the tangent plane.  One can correct for this in the
% integration weights, but don't worry about that right now: the
% integration error and spde approximation errors are likely much bigger
% than this effect in the setting!
% \item 
% Note that my coordinate system construction assumed that the sphere radius was treated as 1, and not arbitrary R.  Using arbitrary R is fine, one just needs to keep track of where it needs to appear...
% \ei 


\end{document}
